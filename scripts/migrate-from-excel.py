#!/usr/bin/env python3
"""
ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ(Excel) â†’ Supabase ç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ã„æ–¹:
  1. pip install openpyxl supabase
  2. ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š:
     export SUPABASE_URL="https://xxxxx.supabase.co"
     export SUPABASE_SERVICE_KEY="eyJhbG..."
  3. python scripts/migrate-from-excel.py --excel "path/to/çµŒå–¶ç®¡ç†.xlsx" --dry-run
  4. ç¢ºèªå¾Œ: python scripts/migrate-from-excel.py --excel "path/to/çµŒå–¶ç®¡ç†.xlsx"

ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
  --dry-run    SQLã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ã™ã‚‹ã ã‘ï¼ˆDBã«ã¯æŠ•å…¥ã—ãªã„ï¼‰
  --limit N    æœ€åˆã®Nè¡Œã ã‘å‡¦ç†ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
"""

import argparse
import json
import os
import sys
import uuid
from datetime import datetime, date
from decimal import Decimal

import openpyxl

# ============================================================
# ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°å®šç¾©
# Excelåˆ—ç•ªå·(1-indexed) â†’ Supabaseãƒ†ãƒ¼ãƒ–ãƒ«.ã‚«ãƒ©ãƒ å
# ============================================================

CUSTOMER_MAPPING = {
    1: 'application_date',       # ç”³è¾¼æ—¥
    2: 'name',                   # åå‰
    3: 'email',                  # ãƒ¡ãƒ¼ãƒ«
    4: 'phone',                  # é›»è©±ç•ªå·
    5: 'utm_source',             # utm_source
    6: 'utm_medium',             # utm_medium
    7: 'utm_id',                 # utm_id
    8: 'utm_campaign',           # utm_campaign
    9: 'attribute',              # å±æ€§
    10: 'career_history',        # çµŒæ­´
    17: 'initial_channel',       # åˆå›èªçŸ¥çµŒè·¯ â†’ reference_media ã«ã‚‚å…¥ã‚Œã‚‹ãŒåˆ†é›¢
    84: 'karte_email',           # ãƒ¡ã‚¢ãƒ‰ï¼ˆã‚«ãƒ«ãƒ†ï¼‰
    85: 'karte_phone',           # é›»è©±ç•ªå·(ã‚«ãƒ«ãƒ†)
    86: 'birth_date',            # ç”Ÿå¹´æœˆæ—¥
    87: 'name_kana',             # ãƒ•ãƒªã‚¬ãƒŠ
    88: 'target_companies',      # å¿—æœ›ä¼æ¥­
    89: 'target_firm_type',      # å¯¾ç­–ãƒ•ã‚¡ãƒ¼ãƒ ã®ã”æ„å‘
    90: 'initial_level',         # ç”³è¾¼æ™‚ãƒ¬ãƒ™ãƒ«
    93: 'application_reason_karte',  # ç”³è¾¼ã®æ±ºã‚æ‰‹ï¼ˆã‚«ãƒ«ãƒ†ï¼‰
    94: 'program_interest',      # æœ‰æ–™ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¸ã®é–¢å¿ƒ
    95: 'desired_schedule',      # å¸Œæœ›æœŸé–“ãƒ»é »åº¦
    96: 'purchased_content',     # ã”è³¼å…¥ã„ãŸã ã„ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    97: 'parent_support',        # è¦ªå¾¡æ§˜ã‹ã‚‰ã®æ”¯æ´
    98: 'sns_accounts',          # å°±æ´»ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ(X)
    99: 'reference_media',       # å‚è€ƒãƒ¡ãƒ‡ã‚£ã‚¢
    100: 'hobbies',              # è¶£å‘³ãƒ»ç‰¹æŠ€
    101: 'behavioral_traits',    # è¡Œå‹•ç‰¹æ€§
    102: 'other_background',     # ãã®ä»–è¦æœ›ãƒ»ç‰¹è¨˜äº‹é …
    103: 'notes',                # å‚™è€ƒ
    104: 'caution_notes',        # æ³¨æ„äº‹é …
    130: 'transfer_intent',      # è»¢è·æ„å‘
    131: 'university',           # å¤§å­¦åæŠœãå‡ºã—
}

PIPELINE_MAPPING = {
    11: 'agent_interest_at_application',  # ç”³è¾¼æ™‚ç‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (textâ†’bool later)
    12: 'meeting_scheduled_date',  # é¢æ¥äºˆå®šæ™‚æœŸ (ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆã‚ã‚Š)
    13: 'stage',                 # æ¤œè¨çŠ¶æ³ â†’ stage
    14: 'projected_amount',      # å£²ä¸Š(è¦‹è¾¼)
    15: 'decision_factor',       # æ¤œè¨ãƒ»å¤±æ³¨ç†ç”±
    16: 'deal_status',           # å®Ÿæ–½çŠ¶æ³
    18: 'sales_content',         # ç”³ã—è¾¼ã¿ã®æ±ºã‚æ‰‹ â†’ decision_factorçš„
    19: 'sales_date',            # å–¶æ¥­å®Ÿæ–½æ—¥
    20: 'probability',           # ç¢ºåº¦
    21: 'response_date',         # è¿”ç­”æ—¥/ä»®å…¥ä¼šæ—¥
    22: 'sales_person',          # å–¶æ¥­æ‹…å½“
    23: 'sales_content',         # å–¶æ¥­å†…å®¹ (ä¸Šæ›¸ãæ³¨æ„â†’Col18ã¨ãƒãƒ¼ã‚¸)
    24: 'sales_strategy',        # å–¶æ¥­æ–¹é‡
    25: 'jicoo_message',         # jicooãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    26: 'agent_confirmation',    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ©ç”¨æ„å‘
    27: 'marketing_memo',        # ãƒãƒ¼ã‚±ãƒ¡ãƒ¢
    28: 'sales_route',           # çµŒè·¯(å–¶æ¥­æ‹…å½“è¨˜å…¥)
    29: 'comparison_services',   # æ¯”è¼ƒã‚µãƒ¼ãƒ“ã‚¹
    30: 'first_reward_category', # ä¸€æ¬¡å ±é…¬åˆ†é¡
    31: 'performance_reward_category',  # æˆæœå ±é…¬åˆ†é¡
    32: 'lead_time',             # å…¥ä¼šã¾ã§ã®ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ 
    33: 'google_ads_target',     # Googleåºƒå‘Šæˆæœå¯¾è±¡
    17: 'initial_channel',       # åˆå›èªçŸ¥çµŒè·¯
    122: 'alternative_application',  # åˆ¥çµŒç”±ã§ã®å¿œå‹Ÿã®æœ‰ç„¡
    133: 'additional_sales_content',  # [è¿½åŠ æŒ‡å°] å–¶æ¥­å†…å®¹
    134: 'additional_plan',      # [è¿½åŠ æŒ‡å°]ãƒ—ãƒ©ãƒ³
    135: 'additional_discount_info',  # [è¿½åŠ æŒ‡å°]å‰²å¼•åˆ¶åº¦ã®æ¡ˆå†…
    136: 'additional_notes',     # [è¿½åŠ æŒ‡å°]å­¦ã³
}

CONTRACT_MAPPING = {
    34: 'referral_category',     # äººæç´¹ä»‹åŒºåˆ†
    35: 'referral_status',       # ç´¹ä»‹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
    36: 'first_amount',          # ä¸€æ¬¡å ±é…¬è«‹æ±‚äºˆå®šé¡
    37: 'confirmed_amount',      # ç¢ºå®šå£²ä¸Š
    38: 'discount',              # å‰²å¼•
    39: 'progress_sheet_url',    # Progress Sheet
    40: 'enrollment_status',     # å—è¬›çŠ¶æ³
    41: 'plan_name',             # å—è¬›ã‚µãƒ¼ãƒ“ã‚¹å
    43: 'payment_date',          # å…¥é‡‘æ—¥
    119: 'invoice_info',         # è«‹æ±‚æ›¸ç”¨
    121: 'billing_status',       # è«‹æ±‚çŠ¶æ³
    139: 'subsidy_eligible',     # ãƒªã‚¹ã‚­ãƒ£ãƒªè£œåŠ©é‡‘å¯¾è±¡ (textâ†’bool)
    140: 'subsidy_amount',       # è£œåŠ©é‡‘é¡
}

LEARNING_MAPPING = {
    42: 'mentor_name',           # æŒ‡å°ãƒ¡ãƒ³ã‚¿ãƒ¼
    44: 'coaching_start_date',   # æŒ‡å°é–‹å§‹æ—¥
    45: 'coaching_end_date',     # æŒ‡å°çµ‚äº†æ—¥
    46: 'last_coaching_date',    # æœ€çµ‚æŒ‡å°æ—¥
    47: 'contract_months',       # å¥‘ç´„æœˆæ•°
    48: 'total_sessions',        # å¥‘ç´„æŒ‡å°å›æ•°
    49: 'weekly_sessions',       # é€±ã‚ãŸã‚ŠæŒ‡å°æ•°
    50: 'completed_sessions',    # æŒ‡å°å®Œäº†æ•°
    51: 'attendance_rate',       # æ—¥ç¨‹æ¶ˆåŒ–ç‡
    52: 'session_completion_rate',  # æŒ‡å°æ¶ˆåŒ–ç‡
    53: 'progress_text',         # é€²æ—
    54: 'level_fermi',           # æœ€æ–°ãƒ¬ãƒ™ãƒ«(ãƒ•ã‚§ãƒ«ãƒŸ)
    55: 'level_case',            # æœ€æ–°ãƒ¬ãƒ™ãƒ«(ã‚±ãƒ¼ã‚¹)
    56: 'level_mck',             # æœ€æ–°ãƒ¬ãƒ™ãƒ«(McK)
    58: 'selection_status',      # é¸è€ƒçŠ¶æ³
    59: 'level_up_range',        # ãƒ¬ãƒ™ãƒ«ã‚¢ãƒƒãƒ—å¹…
    60: 'interview_timing_at_end',  # é¢æ¥äºˆå®šæ™‚æœŸï¼ˆæŒ‡å°çµ‚äº†æ™‚ç‚¹ï¼‰
    61: 'target_companies_at_end',  # å—é¨“ä¼æ¥­ï¼ˆæŒ‡å°çµ‚äº†æ™‚ç‚¹ï¼‰
    62: 'offer_probability_at_end',  # å†…å®šç¢ºåº¦åˆ¤å®š
    63: 'additional_coaching_proposal',  # è¿½åŠ æŒ‡å°ææ¡ˆ
    64: 'initial_coaching_level',  # æŒ‡å°é–‹å§‹æ™‚ãƒ¬ãƒ™ãƒ«
    65: 'enrollment_form_date',  # å…¥ä¼šãƒ•ã‚©ãƒ¼ãƒ æå‡ºæ—¥
    66: 'coaching_requests',     # æŒ‡å°è¦æœ›
    67: 'enrollment_reason',     # å…¥ä¼šç†ç”±
    69: 'behavior_session1',     # ãƒ“ãƒ˜ã‚¤ãƒ“ã‚¢1å›ç›®
    70: 'behavior_session2',     # ãƒ“ãƒ˜ã‚¤ãƒ“ã‚¢2å›ç›®
    71: 'assessment_session1',   # ã‚¢ã‚»ã‚¹ãƒ¡ãƒ³ãƒˆ1å›ç›®
    72: 'assessment_session2',   # ã‚¢ã‚»ã‚¹ãƒ¡ãƒ³ãƒˆ2å›ç›®
    74: 'extension_days',        # å»¶é•·åˆ†(æ—¥)
    91: 'case_interview_progress',  # ã‚±ãƒ¼ã‚¹é¢æ¥å¯¾ç­–ã®é€²æ—
    92: 'case_interview_weaknesses',  # ã‚±ãƒ¼ã‚¹é¢æ¥ã§è‹¦æ‰‹ãªã“ã¨
    111: 'mentoring_satisfaction',  # ãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°æº€è¶³åº¦
    132: 'start_email_sent',     # å—è¬›é–‹å§‹æ—¥ãƒ¡ãƒ¼ãƒ«é€ä»˜æ¸ˆã¿
}

AGENT_MAPPING = {
    68: 'agent_memo',            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ¥­å‹™ãƒ¡ãƒ¢
    73: 'expected_agent_revenue',  # äººæè¦‹è¾¼å£²ä¸Š
    75: 'offer_company',         # å°±æ´»/è»¢è·æ´»å‹•ã®çµæœãƒ»å†…å®šå…ˆ
    76: 'external_agents',       # åˆ©ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    77: 'hire_rate',             # å…¥ç¤¾è‡³ã‚‹ç‡
    78: 'offer_probability',     # å†…å®šç¢ºåº¦
    79: 'offer_salary',          # æƒ³å®šå¹´å
    80: 'referral_fee_rate',     # ç´¹ä»‹æ–™ç‡
    81: 'margin',                # ãƒãƒ¼ã‚¸ãƒ³
    82: 'placement_date',        # å…¥ç¤¾äºˆå®šæ—¥
    83: 'general_memo',          # ãƒ¡ãƒ¢
    118: 'loss_reason',          # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¤±æ³¨ç†ç”±
    128: 'expected_referral_fee',  # äººæç´¹ä»‹å ±é…¬æœŸå¾…å€¤
    137: 'agent_staff',          # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ‹…å½“è€…
    141: 'placement_confirmed',  # äººæç¢ºå®š
}

# ============================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ============================================================

def clean_value(val):
    """None, ç©ºæ–‡å­—, '#N/A' ç­‰ã‚’å‡¦ç†"""
    if val is None:
        return None
    s = str(val).strip()
    if s in ('', '#N/A', '#REF!', '#VALUE!', '#DIV/0!', '#NAME?', 'None', '-'):
        return None
    return s


def to_date(val):
    """æ—¥ä»˜å‹ã¸ã®å¤‰æ›"""
    if val is None:
        return None
    if isinstance(val, datetime):
        return val.strftime('%Y-%m-%d')
    if isinstance(val, date):
        return val.strftime('%Y-%m-%d')
    s = clean_value(val)
    if s is None:
        return None
    # "2026-02-18 00:00:00" å½¢å¼
    try:
        return datetime.fromisoformat(s.replace(' ', 'T')).strftime('%Y-%m-%d')
    except:
        pass
    return s  # ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä¿å­˜ (ä¾‹: "5æœˆ")


def to_int(val):
    """æ•´æ•°ã¸ã®å¤‰æ›"""
    s = clean_value(val)
    if s is None:
        return None
    try:
        f = float(s)
        return int(f)
    except:
        return None


def to_float(val):
    """å°æ•°ã¸ã®å¤‰æ›"""
    s = clean_value(val)
    if s is None:
        return None
    try:
        return float(s)
    except:
        return None


def to_text(val):
    """ãƒ†ã‚­ã‚¹ãƒˆã¸ã®å¤‰æ›"""
    s = clean_value(val)
    if s is None:
        return None
    # æ•°å€¤ãŒé›»è©±ç•ªå·ã¨ã—ã¦å…¥ã£ã¦ã„ã‚‹å ´åˆ
    if isinstance(val, (int, float)):
        if s.endswith('.0'):
            s = s[:-2]
    return s


def to_bool_text(val):
    """'å¯¾è±¡' â†’ True, etc."""
    s = clean_value(val)
    if s is None:
        return None
    if s in ('å¯¾è±¡', 'TRUE', 'True', 'true', '1', 'ã¯ã„', 'Yes'):
        return True
    return False


def escape_sql(val):
    """SQLæ–‡å­—åˆ—ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—"""
    if val is None:
        return 'NULL'
    if isinstance(val, bool):
        return 'TRUE' if val else 'FALSE'
    if isinstance(val, (int, float)):
        return str(val)
    s = str(val).replace("'", "''")
    # æ”¹è¡Œãƒ»ã‚¿ãƒ–ç­‰ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ï¼ˆSQLãŒé€”åˆ‡ã‚Œãªã„ã‚ˆã†ã«ï¼‰
    s = s.replace('\r\n', '\\n').replace('\r', '\\n').replace('\n', '\\n')
    s = s.replace('\t', '\\t')
    return f"E'{s}'"


# ============================================================
# è¡Œãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å„ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨ã®dictã‚’ä½œã‚‹
# ============================================================

def extract_customer(row, customer_id):
    """é¡§å®¢DBè¡Œ â†’ customers ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨dict"""
    data = {'id': customer_id}
    for col_idx, db_col in CUSTOMER_MAPPING.items():
        val = row[col_idx - 1] if col_idx <= len(row) else None

        if db_col in ('application_date', 'birth_date'):
            t = to_text(val)
            if t:
                d = to_date(val)
                data[db_col] = d if d else t
            else:
                data[db_col] = None
        elif db_col == 'phone':
            data[db_col] = to_text(val)
        elif db_col == 'attribute':
            data[db_col] = to_text(val)
        else:
            data[db_col] = to_text(val)

    return data


def extract_pipeline(row, customer_id):
    """é¡§å®¢DBè¡Œ â†’ sales_pipeline ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨dict"""
    data = {'customer_id': customer_id}

    for col_idx, db_col in PIPELINE_MAPPING.items():
        val = row[col_idx - 1] if col_idx <= len(row) else None

        if db_col == 'agent_interest_at_application':
            t = to_text(val)
            if t:
                data[db_col] = t  # ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä¿å­˜
        elif db_col in ('sales_date', 'response_date', 'status_confirmed_date', 'status_final_date'):
            # æ—¥ä»˜å¤‰æ›ã‚’è©¦ã¿ã€å¤±æ•—ã—ãŸã‚‰ãƒ†ã‚­ã‚¹ãƒˆã®ã¾ã¾ä¿å­˜
            t = to_text(val)
            if t:
                d = to_date(val)
                data[db_col] = d if d else t
            else:
                data[db_col] = None
        elif db_col in ('projected_amount',):
            data[db_col] = to_int(val)
        elif db_col == 'probability':
            data[db_col] = to_float(val)
        elif db_col == 'stage':
            t = to_text(val)
            data[db_col] = t or 'å•ã„åˆã‚ã›'
        elif db_col == 'deal_status':
            t = to_text(val)
            data[db_col] = t or 'æœªå¯¾å¿œ'
        else:
            data[db_col] = to_text(val)

    # Col18 ã¨ Col23 ãŒä¸¡æ–¹ sales_content ã«ãƒãƒƒãƒ—ã•ã‚Œã‚‹å•é¡Œã‚’è§£æ±º
    col18 = to_text(row[17] if len(row) > 17 else None)
    col23 = to_text(row[22] if len(row) > 22 else None)
    if col18 and col23:
        data['decision_factor'] = col18
        data['sales_content'] = col23
    elif col18:
        data['decision_factor'] = col18
    elif col23:
        data['sales_content'] = col23

    return data


def extract_contract(row, customer_id):
    """é¡§å®¢DBè¡Œ â†’ contracts ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨dict"""
    data = {'customer_id': customer_id}

    for col_idx, db_col in CONTRACT_MAPPING.items():
        val = row[col_idx - 1] if col_idx <= len(row) else None

        if db_col == 'payment_date':
            t = to_text(val)
            if t:
                d = to_date(val)
                data[db_col] = d if d else t
            else:
                data[db_col] = None
        elif db_col in ('first_amount', 'confirmed_amount', 'subsidy_amount'):
            data[db_col] = to_int(val)
        elif db_col == 'discount':
            t = to_text(val)
            # å‰²å¼•ã¯é‡‘é¡ã®å ´åˆã¨ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆãŒã‚ã‚‹
            i = to_int(val)
            data['discount'] = i  # æ•°å€¤ãªã‚‰æ•°å€¤
            if i is None and t:
                # ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ"æ¡ˆå†…ãªã—"ç­‰ï¼‰ã®å ´åˆã¯0ã«ã—ã¦ãƒ¡ãƒ¢ã«ä¿å­˜
                data['discount'] = 0
        elif db_col == 'subsidy_eligible':
            data[db_col] = to_bool_text(val)
        elif db_col == 'billing_status':
            t = to_text(val)
            data[db_col] = t or 'æœªè«‹æ±‚'
        else:
            data[db_col] = to_text(val)

    return data


def extract_learning(row, customer_id):
    """é¡§å®¢DBè¡Œ â†’ learning_records ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨dict"""
    data = {'customer_id': customer_id}

    for col_idx, db_col in LEARNING_MAPPING.items():
        val = row[col_idx - 1] if col_idx <= len(row) else None

        if db_col in ('coaching_start_date', 'coaching_end_date', 'last_coaching_date', 'enrollment_form_date'):
            t = to_text(val)
            if t:
                d = to_date(val)
                data[db_col] = d if d else t
            else:
                data[db_col] = None
        elif db_col in ('total_sessions', 'completed_sessions', 'contract_months', 'extension_days'):
            data[db_col] = to_int(val)
        elif db_col in ('attendance_rate', 'session_completion_rate', 'weekly_sessions'):
            data[db_col] = to_float(val)
        else:
            data[db_col] = to_text(val)

    return data


def extract_agent(row, customer_id):
    """é¡§å®¢DBè¡Œ â†’ agent_records ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨dict"""
    data = {'customer_id': customer_id}

    for col_idx, db_col in AGENT_MAPPING.items():
        val = row[col_idx - 1] if col_idx <= len(row) else None

        if db_col == 'placement_date':
            t = to_text(val)
            if t:
                d = to_date(val)
                data[db_col] = d if d else t
            else:
                data[db_col] = None
        elif db_col in ('expected_agent_revenue', 'offer_salary', 'margin', 'expected_referral_fee'):
            data[db_col] = to_int(val)
        elif db_col in ('hire_rate', 'offer_probability', 'referral_fee_rate'):
            data[db_col] = to_float(val)
        else:
            data[db_col] = to_text(val)

    return data


# ============================================================
# SQLç”Ÿæˆ
# ============================================================

def dict_to_insert_sql(table, data):
    """dictã‹ã‚‰INSERTæ–‡ã‚’ç”Ÿæˆ"""
    cols = []
    vals = []
    for k, v in data.items():
        if v is not None:
            cols.append(k)
            vals.append(escape_sql(v))
    return f"INSERT INTO {table} ({', '.join(cols)}) VALUES ({', '.join(vals)});"


# ============================================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ============================================================

def process_customer_db(wb, limit=None):
    """é¡§å®¢DBã‚·ãƒ¼ãƒˆã‚’å‡¦ç†"""
    ws = wb['é¡§å®¢DB(new)']
    results = {
        'customers': [],
        'sales_pipeline': [],
        'contracts': [],
        'learning_records': [],
        'agent_records': [],
    }
    customer_email_to_id = {}
    skipped = 0

    for i, row in enumerate(ws.iter_rows(values_only=True)):
        if i == 0:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚¹ã‚­ãƒƒãƒ—
            continue
        if limit and i > limit:
            break

        row = list(row)

        # åå‰ãŒç©ºãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
        name = to_text(row[1] if len(row) > 1 else None)
        if not name:
            skipped += 1
            continue

        customer_id = str(uuid.uuid4())
        email = to_text(row[2] if len(row) > 2 else None)
        if email:
            customer_email_to_id[email.lower()] = customer_id

        # å„ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        customer_data = extract_customer(row, customer_id)
        results['customers'].append(customer_data)

        pipeline_data = extract_pipeline(row, customer_id)
        if pipeline_data:
            pipeline_data['id'] = str(uuid.uuid4())
            results['sales_pipeline'].append(pipeline_data)

        contract_data = extract_contract(row, customer_id)
        if contract_data:
            contract_data['id'] = str(uuid.uuid4())
            results['contracts'].append(contract_data)

        learning_data = extract_learning(row, customer_id)
        if learning_data:
            learning_data['id'] = str(uuid.uuid4())
            results['learning_records'].append(learning_data)

        agent_data = extract_agent(row, customer_id)
        if agent_data:
            agent_data['id'] = str(uuid.uuid4())
            results['agent_records'].append(agent_data)

    print(f"  é¡§å®¢DB: {len(results['customers'])} customers, {skipped} skipped")
    print(f"  Pipeline: {len(results['sales_pipeline'])} records")
    print(f"  Contracts: {len(results['contracts'])} records")
    print(f"  Learning: {len(results['learning_records'])} records")
    print(f"  Agent: {len(results['agent_records'])} records")

    return results, customer_email_to_id


def process_apps(wb, customer_email_to_id, limit=None):
    """Appsã‚·ãƒ¼ãƒˆã‚’å‡¦ç†"""
    ws = wb['Apps']
    results = []

    for i, row in enumerate(ws.iter_rows(values_only=True)):
        if i == 0:
            continue
        if limit and i > limit:
            break

        row = list(row)
        email = to_text(row[2] if len(row) > 2 else None)
        customer_id = customer_email_to_id.get(email.lower()) if email else None

        data = {
            'id': str(uuid.uuid4()),
            'plan_name': to_text(row[0] if len(row) > 0 else None),
            'payment_type': to_text(row[1] if len(row) > 1 else None),
            'email': email,
            'customer_name': to_text(row[3] if len(row) > 3 else None),
            'purchase_date': to_date(row[4] if len(row) > 4 else None),
            'status': to_text(row[5] if len(row) > 5 else None),
            'amount': to_int(row[6] if len(row) > 6 else None),
            'next_billing_date': to_text(row[7] if len(row) > 7 else None),
            'memo': to_text(row[8] if len(row) > 8 else None),
            'installment_amount': to_int(row[9] if len(row) > 9 else None),
            'installment_count': to_int(row[10] if len(row) > 10 else None),
            'period': to_text(row[11] if len(row) > 11 else None),
            'customer_id': customer_id,
        }
        results.append(data)

    print(f"  Apps: {len(results)} payment records")
    return results


def process_bank(wb, customer_email_to_id, limit=None):
    """éŠ€è¡Œã‚·ãƒ¼ãƒˆã‚’å‡¦ç†"""
    ws = wb['éŠ€è¡Œ']
    results = []

    for i, row in enumerate(ws.iter_rows(values_only=True)):
        if i == 0:
            continue
        if limit and i > limit:
            break

        row = list(row)
        email = to_text(row[8] if len(row) > 8 else None)
        customer_id = customer_email_to_id.get(email.lower()) if email else None

        data = {
            'id': str(uuid.uuid4()),
            'transfer_date': to_date(row[0] if len(row) > 0 else None),
            'period': to_date(row[1] if len(row) > 1 else None),
            'buyer_name': to_text(row[2] if len(row) > 2 else None),
            'product': to_text(row[3] if len(row) > 3 else None),
            'amount': to_int(row[4] if len(row) > 4 else None),
            'list_price': to_int(row[5] if len(row) > 5 else None),
            'discounted_price': to_int(row[6] if len(row) > 6 else None),
            'genre': to_text(row[7] if len(row) > 7 else None),
            'email': email,
            'status': to_text(row[9] if len(row) > 9 else None),
            'customer_id': customer_id,
        }
        results.append(data)

    print(f"  éŠ€è¡Œ: {len(results)} bank transfer records")
    return results


CHUNK_SIZE = 500  # 1ãƒ•ã‚¡ã‚¤ãƒ«ã‚ãŸã‚Šã®æœ€å¤§ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°


def write_table_sql(dir_path, seq, table_name, records):
    """ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥ã«SQLåˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›ï¼ˆ500ä»¶ãšã¤ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ï¼‰"""
    if len(records) <= CHUNK_SIZE:
        filename = f"{seq:02d}_{table_name}.sql"
        filepath = os.path.join(dir_path, filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"-- {table_name} ({len(records)} records)\n")
            f.write(f"-- ç”Ÿæˆæ—¥æ™‚: {datetime.now().isoformat()}\n\n")
            f.write("BEGIN;\n\n")
            for data in records:
                f.write(dict_to_insert_sql(table_name, data) + '\n')
            f.write("\nCOMMIT;\n")
        print(f"  {filename}: {len(records)} records")
    else:
        chunks = [records[i:i + CHUNK_SIZE] for i in range(0, len(records), CHUNK_SIZE)]
        for ci, chunk in enumerate(chunks):
            suffix = chr(ord('a') + ci)  # a, b, c, ...
            filename = f"{seq:02d}{suffix}_{table_name}.sql"
            filepath = os.path.join(dir_path, filename)
            start = ci * CHUNK_SIZE + 1
            end = start + len(chunk) - 1
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(f"-- {table_name} (records {start}-{end} / {len(records)})\n")
                f.write(f"-- ç”Ÿæˆæ—¥æ™‚: {datetime.now().isoformat()}\n\n")
                f.write("BEGIN;\n\n")
                for data in chunk:
                    f.write(dict_to_insert_sql(table_name, data) + '\n')
                f.write("\nCOMMIT;\n")
            print(f"  {filename}: {len(chunk)} records ({start}-{end})")


def generate_sql(results, payments, bank_transfers, output_path):
    """ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥ã«SQLåˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›"""
    dir_path = os.path.dirname(output_path) or 'scripts'
    sql_dir = os.path.join(dir_path, 'migration_sql')
    os.makedirs(sql_dir, exist_ok=True)

    print(f"\nSQLåˆ†å‰²å‡ºåŠ›å…ˆ: {sql_dir}/")

    # 0: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—SQL
    cleanup_path = os.path.join(sql_dir, '00_cleanup.sql')
    with open(cleanup_path, 'w', encoding='utf-8') as f:
        f.write("-- æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ï¼ˆå¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã®é †åºã§ï¼‰\n")
        f.write(f"-- ç”Ÿæˆæ—¥æ™‚: {datetime.now().isoformat()}\n\n")
        f.write("DELETE FROM agent_records;\n")
        f.write("DELETE FROM learning_records;\n")
        f.write("DELETE FROM contracts;\n")
        f.write("DELETE FROM sales_pipeline;\n")
        f.write("DELETE FROM payments;\n")
        f.write("DELETE FROM bank_transfers;\n")
        f.write("DELETE FROM customers;\n")
    print(f"  00_cleanup.sql: DELETEæ–‡")

    # ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥ã«åˆ†å‰²å‡ºåŠ›
    tables = [
        (1, 'customers', results['customers']),
        (2, 'sales_pipeline', results['sales_pipeline']),
        (3, 'contracts', results['contracts']),
        (4, 'learning_records', results['learning_records']),
        (5, 'agent_records', results['agent_records']),
        (6, 'payments', payments),
        (7, 'bank_transfers', bank_transfers),
    ]

    for seq, table_name, records in tables:
        write_table_sql(sql_dir, seq, table_name, records)

    print(f"\nå®Ÿè¡Œé †åº:")
    print(f"  1. 00_cleanup.sql      â† æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å‰Šé™¤")
    print(f"  2. 01_customers.sql    â† é¡§å®¢ï¼ˆå…ˆã«æŠ•å…¥: å¤–éƒ¨ã‚­ãƒ¼å‚ç…§å…ƒï¼‰")
    print(f"  3. 02ã€œ07 ã‚’é †ç•ªã«æŠ•å…¥")


def main():
    parser = argparse.ArgumentParser(description='ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ â†’ Supabase ç§»è¡Œ')
    parser.add_argument('--excel', required=True, help='Excelãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('--dry-run', action='store_true', help='SQLãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ã®ã¿')
    parser.add_argument('--limit', type=int, help='å‡¦ç†è¡Œæ•°åˆ¶é™ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰')
    parser.add_argument('--output', default='scripts/migration_data.sql', help='SQLå‡ºåŠ›å…ˆ')
    args = parser.parse_args()

    print(f"ğŸ“‚ Excelãƒ•ã‚¡ã‚¤ãƒ«: {args.excel}")
    print(f"ğŸ”§ ãƒ¢ãƒ¼ãƒ‰: {'dry-run (SQLå‡ºåŠ›ã®ã¿)' if args.dry_run else 'æœ¬ç•ªæŠ•å…¥'}")
    if args.limit:
        print(f"âš ï¸  åˆ¶é™: æœ€åˆã®{args.limit}è¡Œã®ã¿")

    print("\nğŸ“– Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
    wb = openpyxl.load_workbook(args.excel, read_only=True, data_only=True)

    print("\nğŸ“Š é¡§å®¢DBå‡¦ç†ä¸­...")
    results, email_map = process_customer_db(wb, limit=args.limit)

    print("\nğŸ’³ Appså‡¦ç†ä¸­...")
    payments = process_apps(wb, email_map, limit=args.limit)

    print("\nğŸ¦ éŠ€è¡Œå‡¦ç†ä¸­...")
    bank_transfers = process_bank(wb, email_map, limit=args.limit)

    wb.close()

    # SQLå‡ºåŠ›
    generate_sql(results, payments, bank_transfers, args.output)

    total = (
        len(results['customers']) +
        len(results['sales_pipeline']) +
        len(results['contracts']) +
        len(results['learning_records']) +
        len(results['agent_records']) +
        len(payments) +
        len(bank_transfers)
    )
    print(f"\nâœ… åˆè¨ˆ {total} ãƒ¬ã‚³ãƒ¼ãƒ‰")

    if not args.dry_run:
        print("\nâš ï¸  SupabaseæŠ•å…¥ã¯åˆ¥é€”å®Ÿè£…äºˆå®š")
        print("ç¾åœ¨ã¯SQLå‡ºåŠ›ã®ã¿å¯¾å¿œã—ã¦ã„ã¾ã™")
        print(f"ç”Ÿæˆã•ã‚ŒãŸSQLã‚’ç¢ºèªã—ã¦ã€Supabase SQL Editorã§å®Ÿè¡Œã—ã¦ãã ã•ã„:")
        print(f"  {args.output}")


if __name__ == '__main__':
    main()
